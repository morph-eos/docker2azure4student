name: Deploy from sync bundle

on:
  push:
    branches:
      - 'sync/**'
  workflow_dispatch:
    inputs:
      sync_branch:
        description: 'sync/<timestamp>-<sha> branch to deploy'
        required: true
        type: string

permissions:
  contents: write
  id-token: write

jobs:
  deploy:
    runs-on: ubuntu-latest
    outputs:
      sync_branch: ${{ steps.sync-branch.outputs.value }}
      image_tag: ${{ steps.manifest.outputs.image_tag }}
    concurrency:
      group: deploy-${{ github.repository }}-${{ github.event_name == 'workflow_dispatch' && github.event.inputs.sync_branch || github.ref_name }}
      cancel-in-progress: false
    env:
      TF_IN_AUTOMATION: 'true'
      TERRAFORM_WORKING_DIR: '.'
      CONTAINER_SERVICE_NAME: 'app-service'
      CONTAINER_HTTP_PORT: '80'
      CONTAINER_INTERNAL_HTTP_PORT: '8080'
      CONTAINER_HTTPS_PORT: '443'
      CONTAINER_INTERNAL_HTTPS_PORT: '8081'
    steps:
      - name: Determine sync branch
        id: sync-branch
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            if [[ -z "${{ github.event.inputs.sync_branch }}" ]]; then
              echo "sync_branch input is required" >&2
              exit 1
            fi
            BRANCH="${{ github.event.inputs.sync_branch }}"
          else
            BRANCH="${GITHUB_REF#refs/heads/}"
          fi
          echo "value=$BRANCH" >> "$GITHUB_OUTPUT"

      - name: Checkout sync branch
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.sync-branch.outputs.value }}
          fetch-depth: 0

      - name: Restore terraform.tfvars from secret
        run: |
          if [[ -z "${{ secrets.TFVARS_B64 }}" ]]; then
            echo "Missing TFVARS_B64 secret" >&2
            exit 1
          fi
          echo "${{ secrets.TFVARS_B64 }}" | base64 -d > terraform.tfvars

      - name: Load deployment secrets
        id: load-secrets
        run: |
          set -euo pipefail
          missing=0
          append_var() {
            local key="$1"
            local value="$2"
            local label="$3"
            local required="${4:-true}"
            if [[ -z "$value" ]]; then
              if [[ "$required" == "true" ]]; then
                echo "Missing secret: $label" >&2
                missing=1
              fi
              return
            fi
            if [[ "$value" == *$'\n'* ]]; then
              printf '%s<<__ENV__\n%s\n__ENV__\n' "$key" "$value" >> "$GITHUB_ENV"
            else
              printf '%s=%s\n' "$key" "$value" >> "$GITHUB_ENV"
            fi
          }

          if [[ -z "${{ secrets.AZURE_CREDENTIALS }}" ]]; then
            echo "Missing secret: AZURE_CREDENTIALS" >&2
            missing=1
          fi
          append_var TF_BACKEND_CONFIG "${{ secrets.TF_BACKEND_CONFIG }}" TF_BACKEND_CONFIG false
          append_var IMAGE_REGISTRY "${{ secrets.IMAGE_REGISTRY }}" IMAGE_REGISTRY
          append_var IMAGE_NAME "${{ secrets.IMAGE_NAME }}" IMAGE_NAME
          append_var REGISTRY_LOGIN_SERVER "${{ secrets.REGISTRY_LOGIN_SERVER }}" REGISTRY_LOGIN_SERVER
          append_var CONTAINER_REGISTRY_USERNAME "${{ secrets.CONTAINER_REGISTRY_USERNAME }}" CONTAINER_REGISTRY_USERNAME
          append_var CONTAINER_REGISTRY_PASSWORD "${{ secrets.CONTAINER_REGISTRY_PASSWORD }}" CONTAINER_REGISTRY_PASSWORD
          append_var VM_SSH_USERNAME "${{ secrets.VM_SSH_USERNAME }}" VM_SSH_USERNAME
          append_var VM_SSH_KEY "${{ secrets.VM_SSH_KEY }}" VM_SSH_KEY
          append_var APP_ENV_VARS_B64 "${{ secrets.APP_ENV_VARS_B64 }}" APP_ENV_VARS_B64

          if [[ $missing -ne 0 ]]; then
            exit 1
          fi
      - name: Azure login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Prepare backend config (optional)
        id: backend
        run: |
          if [[ -n "$TF_BACKEND_CONFIG" ]]; then
            printf '%s\n' "$TF_BACKEND_CONFIG" > backend.hcl
            echo "args=-backend-config=backend.hcl" >> "$GITHUB_OUTPUT"
          else
            echo "args=" >> "$GITHUB_OUTPUT"
          fi

      - name: Terraform init
        working-directory: ${{ env.TERRAFORM_WORKING_DIR }}
        run: |
          terraform init -input=false ${{ steps.backend.outputs.args }}

      - name: Export Terraform vars for workflow
        id: tfvars-meta
        working-directory: ${{ env.TERRAFORM_WORKING_DIR }}
        run: |
          set -euo pipefail
          python ./scripts/tfvars_meta.py terraform.tfvars subscription_id environment_name vm_public_ip_static > vars.tmp
          while IFS='=' read -r key value; do
            echo "${key}=${value}" >> "$GITHUB_OUTPUT"
            case "$key" in
              subscription_id)
                echo "AZURE_SUBSCRIPTION_ID=${value}" >> "$GITHUB_ENV"
                ;;
              environment_name)
                echo "ENVIRONMENT_NAME=${value}" >> "$GITHUB_ENV"
                ;;
              vm_public_ip_static)
                echo "VM_PUBLIC_IP_STATIC=${value}" >> "$GITHUB_ENV"
                ;;
            esac
          done < vars.tmp
          rm vars.tmp

      - name: Import existing Azure resources
        working-directory: ${{ env.TERRAFORM_WORKING_DIR }}
        env:
          AZURE_SUBSCRIPTION_ID: ${{ steps.tfvars-meta.outputs.subscription_id }}
          ENVIRONMENT_NAME: ${{ steps.tfvars-meta.outputs.environment_name }}
        run: |
          set -euo pipefail

          tf_contains() {
            terraform state list 2>/dev/null | grep -q "^$1$"
          }

          import_if_exists() {
            local address="$1"
            local resource_id="$2"
            local skip_check="${3:-false}"
            if [[ -z "$resource_id" ]]; then
              echo "Skipping $address: resource id not provided"
              return
            fi
            if tf_contains "$address"; then
              echo "State already tracks $address"
              return
            fi
            if [[ "$skip_check" != "true" ]]; then
              if ! az resource show --ids "$resource_id" >/dev/null 2>&1; then
                echo "Azure resource not found for $address ($resource_id)"
                return
              fi
            fi
            echo "Importing $address"
            terraform import "$address" "$resource_id"
          }

          env_name="${ENVIRONMENT_NAME:-student-app}"
          normalized=$(printf '%s' "$env_name" | tr '[:upper:]' '[:lower:]')
          normalized=${normalized// /-}
          prefix=${normalized:0:45}
          subscription="/subscriptions/${AZURE_SUBSCRIPTION_ID}"
          rg_name="${prefix}-rg"
          rg_id="${subscription}/resourceGroups/${rg_name}"

          rg_exists=$(az group show --name "$rg_name" --subscription "$AZURE_SUBSCRIPTION_ID" --query id -o tsv || true)
          import_if_exists "azurerm_resource_group.main" "$rg_exists"

          vnet_name="${prefix}-vnet"
          vnet_id=$(az network vnet show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$vnet_name" --query id -o tsv || true)
          import_if_exists "azurerm_virtual_network.main" "$vnet_id"

          subnet_name="${prefix}-vm-subnet"
          subnet_id=$(az network vnet subnet show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" --vnet-name "$vnet_name" -n "$subnet_name" --query id -o tsv || true)
          import_if_exists "azurerm_subnet.vm" "$subnet_id"

          nsg_name="${prefix}-vm-nsg"
          nsg_id=$(az network nsg show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$nsg_name" --query id -o tsv || true)
          import_if_exists "azurerm_network_security_group.vm" "$nsg_id"

          pip_name="${prefix}-vm-ip-static"
          pip_id=$(az network public-ip show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$pip_name" --query id -o tsv || true)
          if [[ -z "$pip_id" ]]; then
            pip_name="${prefix}-vm-ip-dynamic"
            pip_id=$(az network public-ip show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$pip_name" --query id -o tsv || true)
          fi
          import_if_exists "azurerm_public_ip.vm" "$pip_id"

          nic_name="${prefix}-vm-nic"
          nic_id=$(az network nic show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$nic_name" --query id -o tsv || true)
          import_if_exists "azurerm_network_interface.vm" "$nic_id"

          if [[ -n "$nic_id" && -n "$nsg_id" ]]; then
            import_if_exists "azurerm_network_interface_security_group_association.vm" "${nic_id}|${nsg_id}" true
          fi

          vm_name="${prefix}-vm"
          vm_id=$(az vm show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$vm_name" --query id -o tsv || true)
          import_if_exists "azurerm_linux_virtual_machine.app" "$vm_id"

          auto_name="${prefix}-aa"
          auto_id=$(az automation account show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$auto_name" --query id -o tsv || true)
          if [[ -n "$auto_id" ]]; then
            import_if_exists "azurerm_automation_account.ops[0]" "$auto_id"
            import_if_exists "azurerm_automation_module.az_accounts[0]" "${auto_id}/modules/Az.Accounts"
            import_if_exists "azurerm_automation_module.az_compute[0]" "${auto_id}/modules/Az.Compute"
            import_if_exists "azurerm_automation_module.az_postgresql[0]" "${auto_id}/modules/Az.PostgreSql"

            delete_schedule() {
              local schedule_name="$1"
              if az automation schedule show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" --automation-account-name "$auto_name" --name "$schedule_name" >/dev/null 2>&1; then
                az automation schedule delete --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" --automation-account-name "$auto_name" --name "$schedule_name" --yes >/dev/null
                echo "Deleted automation schedule $schedule_name"
              else
                echo "Schedule $schedule_name not found, skipping"
              fi
            }

            delete_runbook() {
              local runbook_name="$1"
              if az automation runbook show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" --automation-account-name "$auto_name" --name "$runbook_name" >/dev/null 2>&1; then
                az automation runbook delete --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" --automation-account-name "$auto_name" --name "$runbook_name" --yes >/dev/null
                echo "Deleted automation runbook $runbook_name"
              else
                echo "Runbook $runbook_name not found, skipping"
              fi
            }

            delete_schedule "${prefix}-vm-start"
            delete_schedule "${prefix}-vm-stop"
            delete_schedule "${prefix}-db-backup"
            delete_schedule "${prefix}-snapshot-cleanup"

            delete_runbook "${prefix}-start-vm"
            delete_runbook "${prefix}-stop-vm"
            delete_runbook "${prefix}-db-backup"
            delete_runbook "${prefix}-snapshot"
            delete_runbook "${prefix}-snapshot-cleanup"

            auto_principal=$(az automation account show --subscription "$AZURE_SUBSCRIPTION_ID" -g "$rg_name" -n "$auto_name" --query identity.principalId -o tsv || true)
            if [[ -n "$auto_principal" ]]; then
              role_assignment=$(az role assignment list --subscription "$AZURE_SUBSCRIPTION_ID" --assignee-object-id "$auto_principal" --scope "$rg_id" --query '[0].id' -o tsv || true)
              import_if_exists "azurerm_role_assignment.automation_rg[0]" "$role_assignment"
            fi
          fi

          pg_id=$(az resource list --subscription "$AZURE_SUBSCRIPTION_ID" --resource-group "$rg_name" \
            --resource-type "Microsoft.DBforPostgreSQL/flexibleServers" --query "[0].id" -o tsv || true)
          if [[ -n "$pg_id" ]]; then
            import_if_exists "azurerm_postgresql_flexible_server.db" "$pg_id"
            pg_name=$(basename "$pg_id")
            suffix=${pg_name##${prefix}-pg-}
            if [[ -n "$suffix" && "$suffix" != "$pg_name" ]] && ! tf_contains "random_string.db_suffix"; then
              terraform import random_string.db_suffix "$suffix"
            fi
            import_if_exists "azurerm_postgresql_flexible_server_database.app_db" "${pg_id}/databases/appdb"
            import_if_exists "azurerm_postgresql_flexible_server_firewall_rule.azure_services" "${pg_id}/firewallRules/allow-azure-services"
            if [[ "${VM_PUBLIC_IP_STATIC,,}" == "true" ]]; then
              import_if_exists "azurerm_postgresql_flexible_server_firewall_rule.vm_public_ip[0]" "${pg_id}/firewallRules/allow-vm"
            else
              echo "Skipping VM firewall rule import: vm_public_ip_static is false"
            fi
          fi

      - name: Terraform apply
        working-directory: ${{ env.TERRAFORM_WORKING_DIR }}
        run: terraform apply -input=false -auto-approve

      - name: Extract Terraform outputs
        id: tf-outputs
        working-directory: ${{ env.TERRAFORM_WORKING_DIR }}
        run: |
          VM_IP=$(terraform output -raw vm_public_ip)
          if [[ -z "$VM_IP" ]]; then
            echo "Unable to read vm_public_ip output" >&2
            exit 1
          fi
          echo "vm_ip=$VM_IP" >> "$GITHUB_OUTPUT"

      - name: Temporarily open SSH
        id: temp-ssh
        env:
          ENVIRONMENT_NAME: ${{ steps.tfvars-meta.outputs.environment_name }}
        run: |
          set -euo pipefail
          env_name=${ENVIRONMENT_NAME:-student-app}
          normalized=$(printf '%s' "$env_name" | tr '[:upper:]' '[:lower:]')
          normalized=${normalized// /-}
          prefix=${normalized:0:45}
          rg_name="${prefix}-rg"
          nsg_name="${prefix}-vm-nsg"
          RULE_NAME="gha-temp-${{ github.run_id }}"
          # Prefer lowest-available high priority to avoid colliding with existing rules
          existing_priorities=$(az network nsg rule list --resource-group "$rg_name" --nsg-name "$nsg_name" --query '[].priority' -o tsv | tr '\t' '\n' | tr -d '\r' | sed '/^$/d' || true)
          priority=4096
          if [[ -n "$existing_priorities" ]]; then
            while printf '%s\n' "$existing_priorities" | grep -qx "$priority"; do
              priority=$((priority-1))
              if (( priority < 100 )); then
                echo "Unable to find available NSG rule priority between 100-4096" >&2
                exit 1
              fi
            done
          fi
          az network nsg rule create \
            --resource-group "$rg_name" \
            --nsg-name "$nsg_name" \
            --name "$RULE_NAME" \
            --priority "$priority" \
            --direction Inbound \
            --access Allow \
            --protocol Tcp \
            --source-address-prefixes 0.0.0.0/0 \
            --source-port-ranges '*' \
            --destination-address-prefixes '*' \
            --destination-port-ranges 22 \
            --only-show-errors \
            --output none
          echo "rule_name=$RULE_NAME" >> "$GITHUB_OUTPUT"
          echo "rg_name=$rg_name" >> "$GITHUB_OUTPUT"
          echo "nsg_name=$nsg_name" >> "$GITHUB_OUTPUT"

      - name: Read sync manifest
        id: manifest
        working-directory: sync-bundle
        run: |
          IMAGE_TAG=$(jq -r '.imageTag // empty' manifest.json)
          if [[ -z "$IMAGE_TAG" || "$IMAGE_TAG" == "null" ]]; then
            IMAGE_TAG=$(git rev-parse --short=12 HEAD)
          fi
          echo "image_tag=$IMAGE_TAG" >> "$GITHUB_OUTPUT"

      - name: Docker login
        run: |
          if [[ -z "$CONTAINER_REGISTRY_USERNAME" || -z "$CONTAINER_REGISTRY_PASSWORD" ]]; then
            echo "Container registry credentials are missing" >&2
            exit 1
          fi
          echo "$CONTAINER_REGISTRY_PASSWORD" | docker login "$REGISTRY_LOGIN_SERVER" -u "$CONTAINER_REGISTRY_USERNAME" --password-stdin

      - name: Build and push container image
        id: build-push
        working-directory: sync-bundle
        env:
          IMAGE_URI: ${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.manifest.outputs.image_tag }}
        run: |
          docker build -t "$IMAGE_URI" .
          docker push "$IMAGE_URI"
          echo "image_uri=$IMAGE_URI" >> "$GITHUB_OUTPUT"

      - name: Decode application env file
        run: |
          if [[ -z "$APP_ENV_VARS_B64" ]]; then
            echo "APP_ENV_VARS_B64 secret is required" >&2
            exit 1
          fi
          echo "$APP_ENV_VARS_B64" | base64 -d > app.env

      - name: Start SSH agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ env.VM_SSH_KEY }}

      - name: Trust VM host key
        run: |
          set -euo pipefail
          VM_IP="${{ steps.tf-outputs.outputs.vm_ip }}"
          echo "Attempting to fetch SSH host key for $VM_IP"
          for attempt in {1..5}; do
            if ssh-keyscan -H "$VM_IP" >> ~/.ssh/known_hosts 2>/dev/null; then
              echo "Host key added after $attempt attempt(s)."
              exit 0
            fi
            echo "ssh-keyscan failed (attempt $attempt), retrying in 5s..." >&2
            sleep 5
          done
          echo "Warning: unable to retrieve host key; continuing because later SSH commands use StrictHostKeyChecking=no" >&2

      - name: Copy env file to VM
        run: scp -o StrictHostKeyChecking=no app.env ${{ env.VM_SSH_USERNAME }}@${{ steps.tf-outputs.outputs.vm_ip }}:/home/${{ env.VM_SSH_USERNAME }}/app.env

      - name: Deploy container on VM
        env:
          IMAGE_URI: ${{ steps.build-push.outputs.image_uri }}
          VM_IP: ${{ steps.tf-outputs.outputs.vm_ip }}
        run: |
          ssh -o StrictHostKeyChecking=no ${{ env.VM_SSH_USERNAME }}@${VM_IP} "
            set -euo pipefail
            sudo docker login ${REGISTRY_LOGIN_SERVER} -u '${CONTAINER_REGISTRY_USERNAME}' -p '${CONTAINER_REGISTRY_PASSWORD}'
            sudo docker pull ${IMAGE_URI}
            sudo docker stop ${CONTAINER_SERVICE_NAME} || true
            sudo docker rm ${CONTAINER_SERVICE_NAME} || true
            sudo docker run -d --name ${CONTAINER_SERVICE_NAME} --env-file /home/${{ env.VM_SSH_USERNAME }}/app.env -p ${CONTAINER_HTTP_PORT}:${CONTAINER_INTERNAL_HTTP_PORT} -p ${CONTAINER_HTTPS_PORT}:${CONTAINER_INTERNAL_HTTPS_PORT} --restart unless-stopped ${IMAGE_URI}
          "

      - name: Remove temporary SSH rule
        if: always() && steps.temp-ssh.outputs.rule_name != ''
        run: |
          set -euo pipefail
          az network nsg rule delete \
            --resource-group "${{ steps.temp-ssh.outputs.rg_name }}" \
            --nsg-name "${{ steps.temp-ssh.outputs.nsg_name }}" \
            --name "${{ steps.temp-ssh.outputs.rule_name }}" \
            --only-show-errors \
            --output none

  cleanup:
    runs-on: ubuntu-latest
    needs: deploy
    if: always()
    permissions:
      contents: write
    steps:
      - name: Delete sync branch
        if: ${{ startsWith(needs.deploy.outputs.sync_branch, 'sync/') }}
        uses: actions/github-script@v7
        with:
          script: |
            const branch = '${{ needs.deploy.outputs.sync_branch }}';
            try {
              await github.rest.git.deleteRef({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: `heads/${branch}`
              });
              core.info(`Deleted sync branch ${branch}`);
            } catch (error) {
              core.warning(`Could not delete branch ${branch}: ${error.message}`);
            }

      - name: Delete workflow logs on success
        if: ${{ needs.deploy.result == 'success' }}
        uses: actions/github-script@v7
        with:
          script: |
            try {
              await github.rest.actions.deleteWorkflowRunLogs({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: context.runId
              });
              core.info('Deleted workflow logs after successful run.');
            } catch (error) {
              core.warning(`Unable to delete workflow logs: ${error.message}`);
            }
